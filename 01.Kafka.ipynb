{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kafka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основные понятия\n",
    "\n",
    "**Topic** - все сообщения в Kafka приходят в определенный топик, по сути это простой способ организовать и сгруппировать поток сообытий. Каждый топик имеет уникальное имя. \n",
    "\n",
    "**Producers (производитель)**  - компонент системы, клиентское приложение, которое генерирует сообщения и посылает их в определенный топик. \n",
    "\n",
    "**Consumers (потребитель)** - компонент системы, клиентское приложение, которое получает новые сообщения из определенного топика или набора топиков. \n",
    "\n",
    "**Partition** - топик, как логическое понятие, неразделим. Но физически он может состоять из нескольких партиций, которые физически хранятся на нескольких узлах кластера. Когда сообщение приходит в топик, оно физически записывается в только одну партицию.  \n",
    "\n",
    "**Consumer group** - это набор потребителей, которые кооперируются для получения данных из определенного топика. Все партиции топика разделяются между членами группы. По мере входа новых членов группы и ухода старых, партиции перераспределяются так, чтобы каждый член получал пропорциональную долю партиций для чтения. Этот процесс называется ребалансировкой группы.\n",
    "\n",
    "**At-least-once** - гарантируется, что сообщения никогда не теряются, но могут быть доставлены повторно. Если  приложение потоковой обработки падает, то некоторые сообщения могут быть посланы повторно и, следовательно, повторно обработаны. Семантика «хотя бы один раз» включена по умолчанию.\n",
    "\n",
    "**Exactly-once** - сообщения обрабатываются строго один раз. Подобная семантика включается опционально. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск в `Docker`:\n",
    "\n",
    "```bash\n",
    "docker compose -f docker/docker-compose-kafka.yml up\n",
    "```       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from confluent_kafka import Producer, Consumer, TopicPartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC_NAME = \"some_topic\"\n",
    "\n",
    "producer = Producer({\n",
    "        \"bootstrap.servers\": \"localhost:9092\"\n",
    "    })\n",
    "\n",
    "for idx in range(0, 25):\n",
    "    producer.produce(TOPIC_NAME, key=bytes(idx), value=b\"Msg %d\" % idx)\n",
    "    producer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Msg 0'\n",
      "b'Msg 1'\n",
      "b'Msg 2'\n",
      "b'Msg 3'\n",
      "b'Msg 4'\n",
      "b'Msg 5'\n",
      "b'Msg 6'\n",
      "b'Msg 7'\n",
      "b'Msg 8'\n",
      "b'Msg 9'\n",
      "b'Msg 10'\n",
      "b'Msg 11'\n",
      "b'Msg 12'\n",
      "b'Msg 13'\n",
      "b'Msg 14'\n",
      "b'Msg 15'\n",
      "b'Msg 16'\n",
      "b'Msg 17'\n",
      "b'Msg 18'\n",
      "b'Msg 19'\n",
      "b'Msg 20'\n",
      "b'Msg 21'\n",
      "b'Msg 22'\n",
      "b'Msg 23'\n",
      "b'Msg 24'\n"
     ]
    }
   ],
   "source": [
    "consumer = Consumer({\n",
    "    \"bootstrap.servers\": \"localhost:9092\",\n",
    "    \"group.id\": \"group1\",\n",
    "    \"auto.offset.reset\": \"earliest\"\n",
    "})\n",
    "\n",
    "consumer.subscribe([TOPIC_NAME])\n",
    "\n",
    "# tp = TopicPartition(topic=TOPIC_NAME, partition=0, offset=0)\n",
    "# consumer.assign([tp])\n",
    "# consumer.seek(tp)\n",
    "\n",
    "for _ in range(25):\n",
    "    msg = consumer.consume(num_messages=1, timeout=1.0)\n",
    "    if len(msg) > 0:\n",
    "        print(msg[0].value()) \n",
    "\n",
    "consumer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Msg 0'\n",
      "b'Msg 1'\n",
      "b'Msg 2'\n",
      "b'Msg 3'\n",
      "b'Msg 4'\n",
      "b'Msg 5'\n",
      "b'Msg 6'\n",
      "b'Msg 7'\n",
      "b'Msg 8'\n",
      "b'Msg 9'\n",
      "b'Msg 10'\n",
      "b'Msg 11'\n",
      "b'Msg 12'\n",
      "b'Msg 13'\n",
      "b'Msg 14'\n",
      "b'Msg 15'\n",
      "b'Msg 16'\n",
      "b'Msg 17'\n",
      "b'Msg 18'\n",
      "b'Msg 19'\n",
      "b'Msg 20'\n",
      "b'Msg 21'\n",
      "b'Msg 22'\n",
      "b'Msg 23'\n",
      "b'Msg 24'\n"
     ]
    }
   ],
   "source": [
    "consumer = Consumer({\n",
    "    \"bootstrap.servers\": \"localhost:9092\",\n",
    "    \"group.id\": \"group3\",\n",
    "    \"auto.offset.reset\": \"earliest\"\n",
    "})\n",
    "\n",
    "consumer.subscribe([\"some_topic\"])\n",
    "\n",
    "for _ in range(25):\n",
    "    msg = consumer.consume(num_messages=1, timeout=1.0)\n",
    "    if len(msg) > 0:\n",
    "        print(msg[0].value()) \n",
    "\n",
    "consumer.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
